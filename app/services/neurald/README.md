# Canvas | NeuralD

## To eval

### Runtimes

- https://ollama.ai/
- https://github.com/mlc-ai/mlc-llm
- https://github.com/vllm-project/vllm
- https://github.com/mosaicml/llm-foundry
- https://unsloth.ai/
- https://github.com/OpenAccess-AI-Collective/axolotl
- https://memgpt.ai/
- https://developer.nvidia.com/triton-inference-server
- https://github.com/NVIDIA/TensorRT-LLM
- https://skypilot.readthedocs.io/en/latest/
- https://github.com/ggerganov/llama.cpp
- https://github.com/turboderp/exllamav2
- https://tvm.apache.org/
- https://github.com/flexflow/FlexFlow


### Web UI

- https://github.com/SillyTavern/SillyTavern
- https://github.com/theroyallab/tabbyAPI/
- https://github.com/turboderp/exui
- https://github.com/oobabooga/text-generation-webui
- https://github.com/mlc-ai/web-llm/tree/main/examples/simple-chat
- https://github.com/lobehub/lobe-chat
- https://github.com/lm-sys/FastChat
- https://github.com/huggingface/chat-ui
- https://github.com/OmarElgabry/chat.io


### LLM/Agent frameworks

- https://github.com/geekan/MetaGPT
- https://microsoft.github.io/autogen/
- https://microsoft.github.io/autogen/blog/2023/12/01/AutoGenStudio/
- https://github.com/OpenBMB/ChatDev
- https://github.com/joaomdmoura/crewai
- https://github.com/Ironclad/rivet
- https://github.com/langchain-ai/langchain
- https://github.com/ibm/moduleformer
- https://github.com/bentoml/BentoML
- https://github.com/bentoml/OpenLLM
- https://github.com/state-spaces/mamba

### Speech/audio

- https://github.com/fishaudio/Bert-VITS2
- https://github.com/coqui-ai/TTS
- https://news.ycombinator.com/item?id=37514952
- https://github.com/SYSTRAN/faster-whisper
- 

### General tools

- https://github.com/continuedev/continue
- https://docs.librechat.ai/install/configuration/ai_setup.html
- https://github.com/NVIDIA/TensorRT-LLM/tree/main#quick-start
- https://github.com/BerriAI/litellm

### Providers

- https://docs.mistral.ai/platform/client/


### Models

#### Multimodal

- https://github.com/haotian-liu/LLaVA#LLaVA-MPT-7b

#### Coding

- https://deepseekcoder.github.io/
- https://github.com/ise-uiuc/magicoder
- https://huggingface.co/blog/starcoder
- https://github.com/nlpxucan/WizardLM
- https://github.com/fauxpilot/fauxpilot


#### Coding tools

- https://tabby.tabbyml.com/
- https://marketplace.visualstudio.com/items?itemName=TabbyML.vscode-tabby
- https://github.com/xNul/code-llama-for-vscode

#### Mini

- https://github.com/jzhang38/TinyLlama
- https://huggingface.co/microsoft/phi-2


### Quantization

- https://github.com/AutoGPTQ/AutoGPTQ
- https://github.com/artidoro/qlora

### Papers

- [ZeRO-Infinity: Breaking the GPU Memory Wall
for Extreme Scale Deep Learning](https://arxiv.org/pdf/2104.07857.pdf)
- [Efficient Large-Scale Language Model Training on GPU Clusters
Using Megatron-LM](https://arxiv.org/pdf/2104.04473.pdf)
- [SQUEEZELLM: DENSE-AND-SPARSE QUANTIZATION](https://arxiv.org/pdf/2306.07629v2.pdf)


### Snippets

```bash
# Deepseek coder test 
$ ollama run deepseek-coder:6.7b
# Or via a OpenAI compatible API
$ pip install litellm
$ litellm --model deepseek-coder:6.7b
# Use any GPT plugin to integrate with your editor

```
